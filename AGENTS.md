# RAG Pipeline

## Project Structure

The agents are organized within the following directory structure:

```
pyrag/
â”œâ”€â”€ src/pyrag/              # Core agent implementations
â”‚   â”œâ”€â”€ pipeline.py         # RAG pipeline coordinator
â”‚   â”œâ”€â”€ cli.py              # CLI interface
â”‚   â”œâ”€â”€ config.py           # Configuration
â”‚   â””â”€â”€ utils.py            # Utilities
â”œâ”€â”€ tests/                  # Testing framework
â”œâ”€â”€ scripts/                # Scripts
â”œâ”€â”€ .github/workflows/      # CI/CD automation agents
â”‚   â””â”€â”€ test.yml            # GitHub Actions test agent
â””â”€â”€ Makefile                # Development agent orchestration
```

## Development Workflows

### Make Targets for Agent Management

The Makefile provides automated workflows for managing agents:

- **`make qa`**: Run all quality assurance agents (format + lint + test)
- **`make lint`**: Execute ruff linting agent
- **`make format`**: Run code formatting and auto-fix agent
- **`make test`**: Execute full test agent suite
- **`make build`**: Package building agent
- **`make run`**: CLI agent execution with arguments
- **`make install`**: Dependency management agent
- **`make clean`**: Cleanup and maintenance agent

### Development Protocol

**âš ï¸ IMPORTANT: Always run `make qa` after making any changes to the codebase.**

This ensures:
- ðŸŽ¨ Code is properly formatted
- ðŸ” All linting rules are satisfied
- ðŸ§ª Tests pass and functionality is verified
- ðŸ“¦ The codebase remains in deployable state

**âš ï¸ IMPORTANT: Never suppress warnings.**

This ensures:
- We do not ignore severe issues
- We stay future-proof by considering deprecated features

### Example Usage

```bash
# REQUIRED: Run after any code changes
make qa

# Execute RAG pipeline agent with specific query
make run ARGS="https://arxiv.org/pdf/2408.09869 --query 'AI models'"

# Test agent functionality
make test

# Clean agent artifacts
make clean
```

## Technical Notes

### Token Length Warnings
The PyRAG pipeline may show warnings like:
```
Token indices sequence length is longer than the specified maximum sequence length for this model (584 > 512)
```

**This is expected behavior** according to Docling documentation. The `HybridChunker` triggers these warnings during token counting (not actual processing) to assess chunk sizes before splitting. The actual output chunks respect the configured limits.

### LangChain Integration Best Practices
- **Embedding/Tokenizer Compatibility**: Use the same model for both `HuggingFaceEmbeddings` and `HuggingFaceTokenizer.from_pretrained()` to ensure tokenization consistency with the embedding model
- **Supported Models**: All sentence-transformers models support this approach as they share the same underlying tokenizer architecture
- **Performance**: This pattern avoids double model loading and maintains tokenization consistency across the pipeline